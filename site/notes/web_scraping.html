<!DOCTYPE html>
<html>
<head>
  <link href='https://fonts.googleapis.com/css?family=Roboto:400,700' rel='stylesheet' type='text/css'>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
<link rel="stylesheet" href="https://skiadas.github.io/css/course.css" type="text/css" />
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>
<h1 id="web-scraping">Web Scraping</h1>
<p>In this section we will learn about Web Scraping and how to use it to collect information from web-pages.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="http://acmsel.safaribooksonline.com/9781491910290">Web Scraping with Python</a> chapters 1 through 3</li>
<li><a href="http://docs.python-requests.org/en/master/">Python's <code>requests</code> library</a></li>
<li><a href="https://www.crummy.com/software/BeautifulSoup/">Python's <code>BeautifulSoup</code> library</a></li>
</ul>
<h2 id="notes">Notes</h2>
<p>Web Scraping is the process of extracting data from web pages. This consists of a number of activities:</p>
<ul>
<li>Programmatically access a web page's content.</li>
<li>Optionally, submit query data by programmatically filling out a form.</li>
<li>Programmatically detect and follow links on the web page.</li>
<li>Parse and process a page's HTML content and extract key information.</li>
</ul>
<p>This would typically involve two libraries:</p>
<ul>
<li>A library to make HTTP requests, like Python's <a href="http://docs.python-requests.org/en/master/"><code>requests</code> library</a>.</li>
<li>A library to parse and process web-pages. We will use Python's <a href="https://www.crummy.com/software/BeautifulSoup/"><code>BeautifulSoup</code> library</a>.</li>
</ul>
<h3 id="web-scraping-vs-apis">Web Scraping vs APIs</h3>
<p>Web Scraping differs from APIs and Web Services. These APIs are designed to be <em>read by programs</em>, rather than humans. They require a considerable investment on the part of the server, and therefore not all websites with useful information expose that information via an API.</p>
<p>On the other hand, web-scraping processes the same web-page that humans see on a browser, with the only difference that it can read more of the underlying structure of the page, rather than just the visible text. But in essence, web-scraping requires that we program the computer to read information that was designed to be read by humans. This is a somewhat more challenging endeavor, but it can also be applied to more situations, as there are many more web pages out there than there are web services.</p>
<p><em>If you can view it in your browser, you can access it via a Python script</em>.</p>
<dl>
<dt>Web APIs</dt>
<dd>Not human-readable. Optimized for programmatic consumption. Not all sites offer them. Some times expose only limited functionality.
</dd>
<dt>Web Pages</dt>
<dd>Human-readable. Optimized for human consumption. Much more prevalent.
</dd>
</dl>
<h3 id="basic-web-scraping">Basic Web-Scraping</h3>
<p>The basic structure of a web-scraping script would be something like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> requests
<span class="im">import</span> bs4     <span class="co"># Beautiful Soup</span>

http_response <span class="op">=</span> requests.get(<span class="st">&quot;... web page address ...&quot;</span>)

<span class="co"># Possibly consider http_response.status_code to see</span>
<span class="co"># if the page could not be found</span>

page_content <span class="op">=</span> BeautifulSoup(http_response.content)

<span class="co"># Navigate the page_content object</span>
<span class="co"># Extract the desired information</span>
<span class="co"># Print or save results</span></code></pre></div>
<p>As a start example, we will extract information about the world's mountains from the wikipedia page linking all mountains.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> requests
<span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup

base_site <span class="op">=</span> <span class="st">&quot;http://en.wikipedia.org&quot;</span>
mountains_list_age <span class="op">=</span> <span class="st">&quot;/wiki/List_of_mountains_by_elevation&quot;</span>
http_response <span class="op">=</span> requests.get(base_site <span class="op">+</span> mountains_list_age)
bsObj <span class="op">=</span> BeautifulSoup(http_response.content, <span class="st">&quot;html.parser&quot;</span>)
<span class="bu">print</span>(bsObj.prettify())</code></pre></div>
<p>This <code>bsObj</code> represents the entire HTML document, and what you see from the last command is a printout of that HTML document. You can also use your browser's developer tools to see a page.</p>
<p>You will see a nested structure in terms of &quot;tags&quot;, like <code>&lt;html&gt;</code>, <code>&lt;body&gt;</code> etc, which match with closing tags <code>&lt;/html&gt;</code>. This creates a tree-like nested structure, that we can try to dig into. The <em>BeautifulSoup</em> library offers access to this structure in two ways:</p>
<ul>
<li>You can navigate from a tag to its children.</li>
<li>You can target all tags with specific properties (e.g. all &quot;link tags&quot;, the tag with a specific id, etc).</li>
</ul>
For instance we can reach the <code>title</code> tag<code>from the top object by navigating its parent chain: ```python bsObj.html.head.title ``` In this case, given there is only one title tag around, we could also do: ```python bsObj.title ``` The main document contents is all within the</code>
<body>
<code>tag within the</code>
<html>
<p>` tag.</p>
<p>Notice that what you get back is not just the text, but a <strong>tag object</strong>:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">type</span>(bsObj.title)</code></pre></div>
<p>Tag objects in BeautifulSoup provide many functionalities. They all have a &quot;name&quot; property that speaks to the kind of tag we have:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">bsObj.title.name</code></pre></div>
<p>We can also get a look at the attributes, if any:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">bsObj.body.div
bsObj.body.div.attrs
bsObj.body.div[<span class="st">&#39;class&#39;</span>]
bsObj.body.div.get(<span class="st">&#39;class&#39;</span>)     <span class="co">## Safer, returns None if attribute is not there</span></code></pre></div>
<p>We can also access its chidren, i.e. the contained tags. This is an enumerable structure, and we can iterate over it.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">for</span> tag <span class="kw">in</span> bsObj.body.children:
  <span class="bu">print</span>(tag.name)
  <span class="cf">if</span> tag.name <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:
    <span class="bu">print</span>(tag.attrs)</code></pre></div>
<p>Or we can use a list comprehension and turn it into an actual list or do something else:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">elems <span class="op">=</span> [
  tag <span class="cf">for</span> tag <span class="kw">in</span> bsObj.body.children
]</code></pre></div>
<p>Note all the extra &quot;newline&quot; tags. They also count as children. We should try to take them out. These represent the text entries within the document, and they can be detected by the fact that they don't have a name:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">elems <span class="op">=</span> [
  tag
  <span class="cf">for</span> tag <span class="kw">in</span> bsObj.body.children
  <span class="cf">if</span> tag.name <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>
]</code></pre></div>
<p>Based on these tools we can now do more complex operations. For instance notice the &quot;a&quot; tag inside the div tags above. It has an &quot;href&quot; field. We can use it to read the &quot;links&quot;. That's what <code>&lt;a&gt;</code> tags are, links to other pages.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">[
  tag.a.get(<span class="st">&quot;href&quot;</span>)
  <span class="cf">for</span> tag <span class="kw">in</span> bsObj.body.children
  <span class="cf">if</span> tag.name <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>
  <span class="cf">if</span> tag.a <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>
]</code></pre></div>
<p>We can also try to directly grab all &quot;a&quot; links, via the <code>findAll</code> method. This might actually give us more links, as the above method clearly gave us very few links (it only looked at immediate children, not deeper descendants).</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">[
  tag.get(<span class="st">&#39;href&#39;</span>)
  <span class="cf">for</span> tag <span class="kw">in</span> bsObj.find_all(<span class="st">&#39;a&#39;</span>)
]</code></pre></div>
<p>We now need to narrow that list down to the elements we want. Typically this requires:</p>
<ul>
<li>Looking throught the tree structure on the browser, and identifying the elements we want to access.</li>
<li>Identifying some unique property that all those elements share.</li>
<li>Writing code to pick out the elements with that property.</li>
</ul>
<p>For example, we can see that all the entries we are after are inside tables. We could start by targeting those tables, and more specifically the <code>tbody</code> elements that hold the non-header rows of those tables.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">rows <span class="op">=</span> [
  row
  <span class="cf">for</span> tbody <span class="kw">in</span> bsObj.find_all(<span class="st">&#39;tbody&#39;</span>)
  <span class="cf">for</span> row <span class="kw">in</span> tbody.find_all(<span class="st">&#39;tr&#39;</span>)
]
<span class="bu">len</span>(rows)</code></pre></div>
<p>Woah that's a lot of rows! Let us examine one of these rows:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">row0 <span class="op">=</span> rows[<span class="dv">0</span>]</code></pre></div>
<p>Hm that is interesting. Remember that we show a <code>thead</code> element in the browser, and that element contained that heading? It appears that in the processed page, the headings are actually in the <code>tbody</code>: Some times Javascript that runs on the page will change the document structure.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">bsObj.find_all(<span class="st">&#39;thead&#39;</span>)    <span class="co"># There aren&#39;t any!</span></code></pre></div>
<p>So what this means is that we must somehow skip the header rows. The only way to really detect them is by checking one of the values. Notice that they have the <code>th</code> tag in them, while normal table cells have the <code>td</code> tag in them. So we can try to detect that:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">rows <span class="op">=</span> [
  row
  <span class="cf">for</span> tbody <span class="kw">in</span> bsObj.find_all(<span class="st">&#39;tbody&#39;</span>)
  <span class="cf">for</span> row <span class="kw">in</span> tbody.find_all(<span class="st">&#39;tr&#39;</span>)
  <span class="cf">if</span> row.th <span class="kw">is</span> <span class="va">None</span>
]
<span class="bu">len</span>(rows)</code></pre></div>
<p>This is interesting. We had exactly 9 fewer entries, which matches with the 9 divisions of mountains based on height.</p>
<p>Now let us consider each row:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">row0 <span class="op">=</span> rows[<span class="dv">0</span>]
<span class="bu">print</span>(row0)</code></pre></div>
<p>Let's say we want to record the following information for each mountain: Its name, the link to its webpage, its elevation in meters, and which mountain range it is a part of. We'll create a little dictionary from each entry. Our method would be as follows:</p>
<ul>
<li>Figure out how to create the dictionary based on one row.</li>
<li>Turn it into a function and apply it to the entire list via a list comprehension.</li>
</ul>
<p>Let's get started! Here is the various information, which we discovered one at a time with some trial and error:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">{
  <span class="st">&quot;name&quot;</span>: row0.a.text,
  <span class="st">&quot;link&quot;</span>: row0.a.get(<span class="st">&quot;href&quot;</span>),
  <span class="st">&quot;height&quot;</span>: row0.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">1</span>].text,
  <span class="st">&quot;range&quot;</span>: row0.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">3</span>].text
}</code></pre></div>
<p>Hm notice the weird <code>\xa0</code> symbols. These are invisible whitespace characters. We can take them away via a regular expression match:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> re
whitespace <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">&quot;</span><span class="ch">\xa0</span><span class="st">+&quot;</span>)
whitespace.sub(<span class="st">&quot;&quot;</span>, row0.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">3</span>].text)

{
  <span class="st">&quot;name&quot;</span>: row0.a.text,
  <span class="st">&quot;link&quot;</span>: row0.a.get(<span class="st">&quot;href&quot;</span>),
  <span class="st">&quot;height&quot;</span>: row0.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">1</span>].text,
  <span class="st">&quot;range&quot;</span>: whitespace.sub(<span class="st">&quot;&quot;</span>, row0.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">3</span>].text)
}</code></pre></div>
<p>Now that we have something working, we'll try it out on the full list:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">mountains <span class="op">=</span> [
  {
    <span class="st">&quot;name&quot;</span>: row.a.text,
    <span class="st">&quot;link&quot;</span>: row.a.get(<span class="st">&quot;href&quot;</span>),
    <span class="st">&quot;height&quot;</span>: row.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">1</span>].text,
    <span class="st">&quot;range&quot;</span>: whitespace.sub(<span class="st">&quot;&quot;</span>, row.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">3</span>].text)
  }
  <span class="cf">for</span> row <span class="kw">in</span> rows
]</code></pre></div>
<p>Oops, we hit an error! To help diagnose this, we can start by doing a for loop instead, and print information:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">for</span> row <span class="kw">in</span> rows:
  <span class="bu">print</span>({
    <span class="st">&quot;name&quot;</span>: row.a.text,
    <span class="st">&quot;link&quot;</span>: row.a.get(<span class="st">&quot;href&quot;</span>),
    <span class="st">&quot;height&quot;</span>: row.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">1</span>].text,
    <span class="st">&quot;range&quot;</span>: whitespace.sub(<span class="st">&quot;&quot;</span>, row.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">3</span>].text)
  })</code></pre></div>
<p>Looks like the error happened right after the &quot;Santa Fe Baldy&quot; mountain entry. If we search for it we find a &quot;Mount Baldwin&quot; entry following it, but without a link to it. Therefore our <code>row.a.text</code> part failed. We'll need to either use a more complicated function, or read through the beautifulSoup documentation for other methods of getting the text that might work for None objects as well. Or we can also ask our row object for its available methods:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">dir</span>(row0.a)</code></pre></div>
<p>You should see a <code>get_text</code> method there. Let's find out more about it:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">help</span>(row0.a.get_text)</code></pre></div>
<p>You can also search for the method's documentation on the BeautifulSoup page.</p>
<p>Now, let's use that instead and see if it works.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">for</span> row <span class="kw">in</span> rows:
  <span class="bu">print</span>({
    <span class="st">&quot;name&quot;</span>: row.a.get_text(),
    <span class="st">&quot;link&quot;</span>: row.a.get(<span class="st">&quot;href&quot;</span>),
    <span class="st">&quot;height&quot;</span>: row.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">1</span>].text,
    <span class="st">&quot;range&quot;</span>: whitespace.sub(<span class="st">&quot;&quot;</span>, row.find_all(<span class="st">&quot;td&quot;</span>)[<span class="dv">3</span>].text)
  })</code></pre></div>
<p>Nope, it didn't work, as <code>row.a</code> is in fact the <code>None</code> value and doesn't implement the <code>get_text</code> method. We could use <code>row.td.get_text()</code> instead, but this would not fix the <code>link</code> entry for us.</p>
<p>At this point, we would consider making a function that takes a row as input and returns this dictionary:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> row_to_dict(row):
  anchor <span class="op">=</span> row.a
  tds <span class="op">=</span> row.find_all(<span class="st">&quot;td&quot;</span>)
  <span class="cf">return</span> {
    <span class="st">&quot;name&quot;</span>: row.td.get_text(),
    <span class="st">&quot;link&quot;</span>: <span class="va">None</span> <span class="cf">if</span> row.a <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> row.a.get(<span class="st">&quot;href&quot;</span>),
    <span class="st">&quot;height&quot;</span>: tds[<span class="dv">1</span>].text,
    <span class="st">&quot;range&quot;</span>: whitespace.sub(<span class="st">&quot;&quot;</span>, tds[<span class="dv">3</span>].text)
  }

mountains <span class="op">=</span> [
  row_to_dict(row)
  <span class="cf">for</span> row <span class="kw">in</span> rows
]</code></pre></div>
<p>Well done! You've completed your first web scraping. We could now continue to do more with each mountain. For example we could follow the links to each mountain's page, and search for an image of the mountain there, and include that link.</p>
<h3 id="following-links">Following links</h3>
<p>Following links simply requires making a new request. For instance let's take a look at the first mountain, use its link to download its full page, then look at all the image tags on that page:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">m1 <span class="op">=</span> mountains[<span class="dv">0</span>]
http_response1 <span class="op">=</span> requests.get(base_site <span class="op">+</span> m1[<span class="st">&#39;link&#39;</span>])
mObj1 <span class="op">=</span> BeautifulSoup(http_response1.content, <span class="st">&quot;html.parser&quot;</span>)
images <span class="op">=</span> mObj1.find_all(<span class="st">&#39;img&#39;</span>)
pprint(images)</code></pre></div>
<p>Woah there are 104 images on that page. We need to somehow only pick one. We would like this to be the one on the section on the top right.</p>
<p>It looks like the right side always contains a <code>table</code> element with classes <code>infobox</code> and <code>vcard</code>. There are many of these, but the first one is probably the one we want. We could try to target that table element, then grab the first image tag within it:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">sidebar <span class="op">=</span> mObj1.find(<span class="st">&#39;table&#39;</span>, class_<span class="op">=</span><span class="st">&quot;infobox&quot;</span>)
sidebar.find(<span class="st">&#39;img&#39;</span>)</code></pre></div>
<p>Now we'll write a little function that does this: for a dictionary entry for a mountain, it follows the link to the mountain's main page, if there is one, grabs this image tag, then extracts the <code>src</code> link from it.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> update_image_link(mountain):
  <span class="cf">if</span> mountain[<span class="st">&quot;link&quot;</span>] <span class="kw">is</span> <span class="va">None</span>:
    mountain[<span class="st">&quot;image_link&quot;</span>] <span class="op">=</span> <span class="va">None</span>
  <span class="cf">else</span>:
    http_response <span class="op">=</span> requests.get(base_site <span class="op">+</span> mountain[<span class="st">&quot;link&quot;</span>])
    mObj <span class="op">=</span> BeautifulSoup(http_response.content, <span class="st">&quot;html.parser&quot;</span>)
    sidebar <span class="op">=</span> mObj.find(<span class="st">&#39;table&#39;</span>, class_<span class="op">=</span><span class="st">&quot;infobox&quot;</span>)
    img <span class="op">=</span> sidebar.find(<span class="st">&#39;img&#39;</span>)
    mountain[<span class="st">&quot;image_link&quot;</span>] <span class="op">=</span> img.get(<span class="st">&quot;src&quot;</span>)

<span class="cf">for</span> mountain <span class="kw">in</span> mountains:
  <span class="bu">print</span>(mountain[<span class="st">&quot;name&quot;</span>])
  update_image_link(mountain)</code></pre></div>
<p>We added the printout to see the process as it goes. This script will take a while to run as it has to access over 1400 different webpages.</p>
<p>And we see it got stuck on <code>Batura IV</code>. Looking at this name in the initial webpage shows a &quot;red link&quot;. This points to a non-existing page, so of course we won't find any images there. We have two ways to try to fix this:</p>
<ul>
<li>Detect which links point to those pages, and exclude them.</li>
<li>Be more robust in our search for the image link on that page, namely check that the sidebar exists before trying to find its image, and checking that the image exists before trying to get its source link.</li>
</ul>
<p>In this case we can follow either approach. We will try them both. Notice how the link for <code>Batura IV</code> has <code>index.php</code> as a part of it. Surely the valid links won't contain that. So we can use a regular expression to look for that:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">indexRegEx <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">&quot;index.php&quot;</span>)
<span class="kw">def</span> update_image_link(mountain):
  <span class="cf">if</span> mountain[<span class="st">&quot;link&quot;</span>] <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="op">\</span>
        indexRegEx.search(mountain[<span class="st">&quot;link&quot;</span>]) <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:
    mountain[<span class="st">&quot;image_link&quot;</span>] <span class="op">=</span> <span class="va">None</span>
    <span class="cf">return</span>
  http_response <span class="op">=</span> requests.get(base_site <span class="op">+</span> mountain[<span class="st">&quot;link&quot;</span>])
  mObj <span class="op">=</span> BeautifulSoup(http_response.content, <span class="st">&quot;html.parser&quot;</span>)
  sidebar <span class="op">=</span> mObj.find(<span class="st">&#39;table&#39;</span>, class_<span class="op">=</span><span class="st">&quot;infobox&quot;</span>)
  img <span class="op">=</span> sidebar.find(<span class="st">&#39;img&#39;</span>)
  mountain[<span class="st">&quot;image_link&quot;</span>] <span class="op">=</span> img.get(<span class="st">&quot;src&quot;</span>)

<span class="cf">for</span> mountain <span class="kw">in</span> mountains:
  <span class="bu">print</span>(mountain[<span class="st">&quot;name&quot;</span>])
  update_image_link(mountain)</code></pre></div>
<p>Good, that helped us make progress! But now we are stuck on <code>Lungser Kangri</code>. Following its link we see that there is no sidebar in the resulting page. So let's add some safeguards there. As we seem to be setting the <code>mountain[&quot;link&quot;]</code> to None in many places, let's do it only once instead, at the beginning:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">indexRegEx <span class="op">=</span> re.<span class="bu">compile</span>(<span class="st">&quot;index.php&quot;</span>)
<span class="kw">def</span> update_image_link(mountain):
  mountain[<span class="st">&quot;image_link&quot;</span>] <span class="op">=</span> <span class="va">None</span>
  <span class="cf">if</span> mountain[<span class="st">&quot;link&quot;</span>] <span class="kw">is</span> <span class="va">None</span>:
    <span class="cf">return</span>
  <span class="cf">if</span> indexRegEx.search(mountain[<span class="st">&quot;link&quot;</span>]) <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:
    <span class="cf">return</span>
  http_response <span class="op">=</span> requests.get(base_site <span class="op">+</span> mountain[<span class="st">&quot;link&quot;</span>])
  mObj <span class="op">=</span> BeautifulSoup(http_response.content, <span class="st">&quot;html.parser&quot;</span>)
  sidebar <span class="op">=</span> mObj.find(<span class="st">&#39;table&#39;</span>, class_<span class="op">=</span><span class="st">&quot;infobox&quot;</span>)
  <span class="cf">if</span> sidebar <span class="kw">is</span> <span class="va">None</span>:
    <span class="cf">return</span>
  img <span class="op">=</span> sidebar.find(<span class="st">&#39;img&#39;</span>)
  <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:
    <span class="cf">return</span>
  mountain[<span class="st">&quot;image_link&quot;</span>] <span class="op">=</span> img.get(<span class="st">&quot;src&quot;</span>)

<span class="cf">for</span> mountain <span class="kw">in</span> mountains:
  <span class="bu">print</span>(mountain[<span class="st">&quot;name&quot;</span>])
  update_image_link(mountain)</code></pre></div>
</body>
</html>
